---
title: "Benchmarking {SpeedyMarkov}"
author: "Sam Abbott"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Benchmarking {SpeedyMarkov}}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, comment = "#>",
  fig.width = 7, fig.height = 7, 
  fig.align = "center"
)
```



## Two state Markov model


```{r}
library(SpeedyMarkov)


duration <- 1000
samples <- 100000
```




```{r}
library(SpeedyMarkov)

markov_ce_pipeline(example_two_state_markov(), duration = 100, samples = 100000,
                   sim_type = "base")

```

### R  implementation augmented with Rcpp 

An obvious optimisation of the inner Markov Loop is to rewrite it into C++ code, this can be done easily using the `RcppArmadillo` package which aids in the use of the Armadillo C++ library in R. See [here](https://github.com/seabbs/SpeedyMarkov/blob/master/R/markov_loop.R) for the R implementation and [here](https://github.com/seabbs/SpeedyMarkov/blob/master/src/ArmaSimulateMarkov.cpp) for the C++ implementation.

Profiling this new approach we see a substantial decrease in run-time of around two times compared to the `SpeedyMarkov` R implementation and around 4 times compared to the reference approach. Memory usage has also roughly halved compared to the `SpeedyMarkov` R implementation. This speed up comes with minimal increase in code complexity and should scale extremely well to more complex models - as this would increase computational costs versus the cost of moving data to and from C++. The speed up 

```{r}
library(SpeedyMarkov)
library(profvis)

profvis({
  markov_ce_pipeline(example_two_state_markov(), duration = 100, samples = 100000,
                     sim_type = "armadillo_inner")
})
```

### R implementation further augmented with Rcpp

The next step is to rewrite the entire Markov simulation step into C++ (again using the `RcppArmadillo` package). See [here](https://github.com/seabbs/SpeedyMarkov/blob/master/R/simulate_markov.R) for the R implementation and [here](https://github.com/seabbs/SpeedyMarkov/blob/master/src/ArmaSimulateMarkov.cpp) for the C++ implementation. This implementation now takes around 25% of the time that the reference implementation took with a fraction of the memory overhead.  

Using profiling we see a small speed up (of 20% compared to the previous implementation) and a reduced memory usage (with 50% of the memory footprint) compared to the partial C++ approach above. As the majority of the run-time is still being spent within the simulation function this indicates that increase the efficiency of sampling and/or summarisation would have minimal impact on this example (although it is still worth doing if readability and robustness can be preserved). Much of the computational cost appears to be in accessing and passing sample data to the simulation function. Finding optimised solutions to this could therefore be the next priority. 

```{r}
library(SpeedyMarkov)
library(profvis)

profvis({
  markov_ce_pipeline(example_two_state_markov(), duration = 100, samples = 100000,
                     sim_type = "armadillo_all")
})
```

